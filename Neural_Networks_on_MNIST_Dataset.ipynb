{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Networks on MNIST Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GregoryAlbarian/Neural-Network-using-MNIST/blob/main/Neural_Networks_on_MNIST_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCz9cxAw4_oF"
      },
      "source": [
        "# Neural Networks on MNIST Handwritten Digit Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XHA5xDHkGQVa",
        "outputId": "4ad7c73b-b91e-4bab-a826-7d25dc9b7a43"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"Screen Shot 2021-04-26 at 2.33.41 PM.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "Screen Shot 2021-04-26 at 2.33.41 PM.png",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and Preprocessing Data\n",
        "\n"
      ],
      "metadata": {
        "id": "7kkCySjjgbup"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87-fv4hq0c8d",
        "outputId": "6fb27ba6-2504-44c4-c740-bfe6d10df5af"
      },
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import mnist\n",
        "import keras\n",
        "\n",
        "# load train and test dataset\n",
        "# load dataset\n",
        "import keras\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\n",
        "# Prepare Pixel Data\n",
        "# convert from integers to floats\n",
        "\n",
        "\n",
        "# 0-9 numbered images\n",
        "num_classes = 10\n",
        "\n",
        "# flatten the data\n",
        "# trainX = trainX.reshape(-1, 784) #28*28=784\n",
        "# testX = testX.reshape(-1, 784)\n",
        "\n",
        "train_norm = trainX.astype('float32')\n",
        "test_norm = testX.astype('float32')\n",
        "# normalize to range 0-1\n",
        "train_norm = train_norm / 255.0\n",
        "test_norm = test_norm / 255.0 #Data normalization is an important step which ensures that each input parameter (pixel, in this case)\n",
        "#has a similar data distribution. This makes convergence faster while training the network\n",
        "\n",
        "\n",
        "# one hot encode target values\n",
        "trainY = keras.utils.to_categorical(trainY)\n",
        "testY = keras.utils.to_categorical(testY)\n",
        "train_norm.shape , test_norm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolutional Neural Network (CNN)"
      ],
      "metadata": {
        "id": "xp2Rapzogop0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tySaCmmY3j9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b2b7ad-155c-48d7-c3fd-ecaf1726bc53"
      },
      "source": [
        "# your code goes here\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "# output part of the model\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# fit model\n",
        "\n",
        "# one hot encode target values\n",
        "\n",
        "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "# compile model\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# fit model\n",
        "history = model.fit(trainX, trainY, epochs=32, batch_size=64, validation_data=(testX, testY), verbose=0)\n",
        "_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> 98.910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv8ApcDw3-sQ"
      },
      "source": [
        "### Fully Connected Neural Network (FCNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO8ZXMJe4e6f"
      },
      "source": [
        "# your code goes here "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4tBnLRpgjyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70af0a16-b68f-43af-a5e8-b8e913591d88"
      },
      "source": [
        " building the neural network\n",
        "\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\n",
        "# flatten the data\n",
        "trainX = trainX.reshape(-1, 784) #28*28=784\n",
        "testX = testX.reshape(-1, 784)\n",
        "\n",
        "\n",
        "train_norm = trainX.astype('float32')\n",
        "test_norm = testX.astype('float32')\n",
        "# normalize to range 0-1\n",
        "train_norm = train_norm / 255.0\n",
        "test_norm = test_norm / 255.0 #Data normalization is an important step which ensures that each input parameter (pixel, in this case)\n",
        "#has a similar data distribution. This makes convergence faster while training the network\n",
        "\n",
        "\n",
        "# one hot encode target values\n",
        "trainY = keras.utils.to_categorical(trainY)\n",
        "testY = keras.utils.to_categorical(testY)\n",
        "train_norm.shape , test_norm.shape\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(784, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(240, activation='relu'))\n",
        "model.add(Dense(120, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', # notice this isn't MSE because we're not doing regression\n",
        "    optimizer=SGD(),\n",
        "    metrics=['accuracy'])            # want to monitor accuracy over training\n",
        "\n",
        "\n",
        "# 128 images in each batch\n",
        "batch_size = 128\n",
        "# train for 5 steps\n",
        "epochs = 32\n",
        "\n",
        "history = model.fit(\n",
        "    trainX, trainY,                 # training data to learn from \n",
        "    batch_size=batch_size,            # size of batches\n",
        "    epochs=epochs,                    # how many iterations we train for \n",
        "    validation_data=(testX, testY)) # validation data to test on\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "469/469 [==============================] - 2s 3ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 2/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 3/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 4/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 5/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 6/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 7/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 8/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0976 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 9/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 10/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0982 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 11/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 12/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0972 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 13/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0965 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 14/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 15/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0975 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 16/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 17/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 18/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 19/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 20/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 21/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0963 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 22/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0965 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 23/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 24/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 25/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 26/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 27/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0962 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 28/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 29/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 30/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 31/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 32/32\n",
            "469/469 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0roS-TkNpqnB"
      },
      "source": [
        "__The CNN with VGG block gave better results than the FCNN. This is because the CNN takes into account the placement of parts within the images better using convolutions. I used are 32 epochs for each__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autoencoder"
      ],
      "metadata": {
        "id": "tSOGVuXSg0aX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxYImVWM6z4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2a3e90c-b420-4735-c91c-caa86431f82e"
      },
      "source": [
        "# Your code goes here\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "##### We'll start simple, with a single fully-connected neural layer as encoder and as decoder:\n",
        "\n",
        "# This is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# This is our input image\n",
        "input_img = keras.Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# This model maps an input to its reconstruction\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "\n",
        "autoencoder.summary()\n",
        "\n",
        "############################################################################## Encoder model\n",
        "\n",
        "# This model maps an input to its encoded representation\n",
        "encoder = keras.Model(input_img, encoded)\n",
        "\n",
        "##############################################################################  Decoder model\n",
        "# This is our encoded (32-dimensional) input\n",
        "encoded_input = keras.Input(shape=(encoding_dim,))\n",
        "# Retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# Create the decoder model\n",
        "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
        "############################################################################## \n",
        "decoder.summary()\n",
        "\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=32,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "# Encode and decode some digits\n",
        "# Note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # How many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 784)               25872     \n",
            "=================================================================\n",
            "Total params: 50,992\n",
            "Trainable params: 50,992\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 784)               25872     \n",
            "=================================================================\n",
            "Total params: 25,872\n",
            "Trainable params: 25,872\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(60000, 784)\n",
            "(10000, 784)\n",
            "Epoch 1/32\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3825 - val_loss: 0.1899\n",
            "Epoch 2/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1791 - val_loss: 0.1520\n",
            "Epoch 3/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1483 - val_loss: 0.1333\n",
            "Epoch 4/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1318 - val_loss: 0.1210\n",
            "Epoch 5/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1202 - val_loss: 0.1123\n",
            "Epoch 6/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1124 - val_loss: 0.1062\n",
            "Epoch 7/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1065 - val_loss: 0.1020\n",
            "Epoch 8/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1024 - val_loss: 0.0991\n",
            "Epoch 9/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0996 - val_loss: 0.0969\n",
            "Epoch 10/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0979 - val_loss: 0.0955\n",
            "Epoch 11/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0964 - val_loss: 0.0945\n",
            "Epoch 12/32\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0959 - val_loss: 0.0939\n",
            "Epoch 13/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0951 - val_loss: 0.0936\n",
            "Epoch 14/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0948 - val_loss: 0.0932\n",
            "Epoch 15/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0944 - val_loss: 0.0929\n",
            "Epoch 16/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0939 - val_loss: 0.0928\n",
            "Epoch 17/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0942 - val_loss: 0.0926\n",
            "Epoch 18/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0938 - val_loss: 0.0924\n",
            "Epoch 19/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0936 - val_loss: 0.0923\n",
            "Epoch 20/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0935 - val_loss: 0.0922\n",
            "Epoch 21/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0934 - val_loss: 0.0921\n",
            "Epoch 22/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0932 - val_loss: 0.0921\n",
            "Epoch 23/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0931 - val_loss: 0.0921\n",
            "Epoch 24/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0933 - val_loss: 0.0919\n",
            "Epoch 25/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - val_loss: 0.0919\n",
            "Epoch 26/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0919\n",
            "Epoch 27/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0931 - val_loss: 0.0918\n",
            "Epoch 28/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 29/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 30/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 31/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 32/32\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0931 - val_loss: 0.0917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCfSPP9xz0JV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}